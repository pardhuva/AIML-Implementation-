{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f5949f-a62a-4756-ace8-4178306cbdf3",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn (sklearn)\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of the beautiful sciki-learn library \n",
    "\n",
    "what we're going to cover :\n",
    " 0. An end-end scikit workflow \n",
    " 1. Getting the data ready \n",
    " 2. Choose the right estimator/algorithm for our problems \n",
    " 3. fit the model/algorithm and use it to make predictions on our data \n",
    " 4. Evaluaitng a model \n",
    " 5. improve a model \n",
    " 6. save and load a trained model \n",
    " 7. putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf8ad8-b8ff-4888-b18c-385997f67958",
   "metadata": {},
   "source": [
    " ## 0. An end-to-end scikit-learn workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32cef9d3-da4a-4bbd-9d07-8872b8a80fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets start with data lets do with that heart-disease data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad6a0dd6-b6e5-4810-8fef-736c43b6d6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "5   44    1   2       140   235    0        0      180      0      0.4      1   \n",
       "6   52    1   0       128   204    0        1      156      1      1.0      1   \n",
       "7   57    1   1       110   201    0        1      160      0      1.5      1   \n",
       "8   54    0   1       140   239    0        1      155      1      1.2      1   \n",
       "9   48    1   2       124   255    0        0      173      0      0.0      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       0  \n",
       "5   0     3       1  \n",
       "6   2     3       0  \n",
       "7   1     2       1  \n",
       "8   1     2       0  \n",
       "9   0     2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the data ready \n",
    "import pandas as pd \n",
    "heart_disease = pd.read_csv(\"heart_disease_sample (1).csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f22a4df-3014-4aad-9d7d-ec41ef91f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build a model to predict the target(0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d3ba12d-08a1-4730-83b6-bf4ae05a8b03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hear_disease' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create X (features matrix)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mhear_disease\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m X\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create Y (labels)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hear_disease' is not defined"
     ]
    }
   ],
   "source": [
    "# Create X (features matrix)\n",
    "X = hear_disease.drop(\"target\",axis=1)\n",
    "X\n",
    "\n",
    "# Create Y (labels)\n",
    "Y = heart_disease[\"target\"]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e223785-c4ae-46be-83fa-57e631352fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf280111-1329-4ce6-bc16-6d93bfc8ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Choose the right model and hyperparameters\n",
    "# in this case it is a classification problem as we have to predict whether a heart disease or not \n",
    "# hyperparameters are like dials on a model that you can tune to make it better or worse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1696364-f43a-4bd3-9f34-b77fc92d968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use random forest it is a classification model \n",
    "# it is capable of learning patterns and data and then classifying \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)    # model\n",
    "\n",
    "# we'll keep the default hyperparameters \n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08919c6e-ea31-4fab-b80e-46c00b751e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we are done choosing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6a8fe-fcbf-4b13-95d7-ead89262695c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89207e-387b-42df-bc89-b69dfa7a49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the model to the training data\n",
    "# we need to train our model on training set and test our model on test set \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "# here test size is 0.2 so 20% test split and 80% train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3405afd-4eb1-4d90-b30c-34300b17b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda80d4-e3eb-4fb6-a6d6-42123e7f362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d4fcf-f275-4ce9-a6a2-c1c357674067",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbee187-eea3-4b69-b9e8-3fa6d89df380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8d105-b917-4ce1-8f3e-e60fb22949c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are actual y labels of test data\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16719d43-fb1e-46ae-a7b8-d6be90fe3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction- lets test the testing data\n",
    "import numpy as np\n",
    "Y_label= clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529fac9-33da-47f5-8557-5e3277c25c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is predicted y labels of test data\n",
    "Y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfca5a4-e601-4f0c-8392-615d18db3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the model on the training data and test data\n",
    "# returns the mean accuracy on teh given data adn labels\n",
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912745a-56ca-4e3f-be01-3c414938800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd322c4-efab-492d-b831-1cbb915016c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the training data got more score because it is trained well on the features 100%\n",
    "# whereas the test data got only one correct and one wrong so 50% so 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecce7a-e822-4ce2-9421-d8a05089c658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f15c8-13d6-49d7-8c44-3179272131a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(Y_test,Y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bebf60-ea99-405e-8cc5-c22d885feb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test,Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561546a-8463-4755-b2a9-f88c4307a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_test,Y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f977-b247-4b22-8018-e93fc0c35c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9177bb5c-a4e3-45d8-bef1-e310642aee51",
   "metadata": {},
   "source": [
    "Random forest is many decision trees voting together \n",
    "n_estimators = number of trees in the forest\n",
    "\n",
    "â€œIf I use 10 trees vs 20 trees vs 30 trees â€¦ 90 trees, how does accuracy change?â€\n",
    "Thatâ€™s called hyperparameter tuning.\n",
    "\n",
    "np.random.seed(43)\n",
    "Random Forest uses randomness,Without this, accuracy may change every run\n",
    "\n",
    "so below we are training model with i deciion drees \n",
    "every loop = new model\n",
    "\n",
    "then testing on unseen test data\n",
    "score-> correct_predictions/total_predictions *100 {...2f}%    # this gives you percentage\n",
    "\n",
    "Accuracy improves as trees increaseâ€¦\n",
    "ðŸ‘‰ Then it may plateau or even drop.\n",
    "\n",
    "Too few trees â†’ underfitting\n",
    "Too many trees â†’ slow, little gain\n",
    "Goal â†’ find sweet spot\n",
    "\n",
    "This is manual hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfdf49-2b5c-49c3-9ef9-13e64c1d4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Improve a model \n",
    "# Try different amount of n_estimators\n",
    "# so lets try to figure out if we can improve our model by adjusting one of the hyper parameters\n",
    "\n",
    "np.random.seed(43)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Trying model with {i} estimate...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train,Y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test,Y_test)* 100:2f}%\")\n",
    "    print(\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68ad09-7f9a-47a5-88b8-719b7acefebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. save a model and load it \n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf,open(\"random_forest_model_1.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378507fe-9b71-4414-841f-d8e01659aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pk1\", \"rb\"))\n",
    "loaded_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a277671-7eb4-4300-bb44-4d739cdb47e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a03e46f5-4220-45cd-8de2-5760d95b5973",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "Load and clean the data\n",
    "Select features (X) and target (y)\n",
    "Choose a suitable model\n",
    "Split the data into training and test sets\n",
    "Train the model using training data\n",
    "Evaluate the model on training and test data\n",
    "Improve the model by tuning hyperparameters\n",
    "Train the final model\n",
    "Save the model using pickle\n",
    "\n",
    "1. Load & prepare the data \n",
    " Load the dataset\n",
    "Clean it (missing values, encoding, scaling if needed)\n",
    "Select features (X) and target (y)\n",
    "\n",
    "2. Choose the model\n",
    "Select an algorithm (e.g. RandomForestClassifier)\n",
    "This is just a starting model, not final\n",
    "\n",
    "3. Split the data\n",
    "X_train, X_test, y_train, y_test\n",
    "Split happens before training\n",
    "Test data must stay untouched\n",
    "\n",
    "4. Fit (train) the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "The model learns patterns here.\n",
    "\n",
    "5. Evaluate the model\n",
    "Evaluate on training data â†’ check overfitting\n",
    "Evaluate on test data â†’ check generalization\n",
    "model.score(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "6. Improve (tune) the model\n",
    "Adjust hyperparameters (n_estimators, max_depth, etc.)\n",
    "Retrain the model\n",
    "Re-evaluate\n",
    "\n",
    "7. Train the final model\n",
    "Use the best hyperparameters\n",
    "Fit again on training data\n",
    "\n",
    "8. Save the model\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))\n",
    "This is done after finalizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e43b48-70d4-4a05-9c32-03c4352a3017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b475deac-c714-474b-8fd8-3f2fd025b0a0",
   "metadata": {},
   "source": [
    "## Debugging warnings in jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92442d48-f8fe-44b0-b955-d946601a721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will not give warning in any cell running\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f528f-2712-4c63-87d3-b7a8974e1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wnat back the warnings you can use \"default\" instead of ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b248dd-4ac4-4c8e-808e-56e50010c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the scikit-learn version \n",
    "import sklearn\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38427efc-49c6-4cba-9d37-42f5d9aed590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to upgrade the sklearn version within conda environment\n",
    "# in the terminal \n",
    "# updating the packages , it should be done on terminal\n",
    "conda update scikit-learn\n",
    "\n",
    "# if you want to check \n",
    "conda list scikit-learn\n",
    "\n",
    "# for searching specifieed packages versions \n",
    "conda search scikit-learn --info\n",
    "\n",
    "# for python verison\n",
    "conda list python \n",
    "\n",
    "# how to install some packages of scikit learn to install more updated versions\n",
    "conda uninstall scikit-learn python \n",
    "\n",
    "# now install again if you want specific verisons \n",
    "conda isntall python = 3.6.9 scikit-learn=1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09b490-8e40-4213-848e-b8c4a68413f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so for warnigns you cna deal in two ways \n",
    "# 1. import that warning and filter those warnings \n",
    "# 2. install those updated packages that supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da856c31-0c6e-45b2-85db-d2e19fd29a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72b6e47e-59d9-4776-84e2-2c88978dd512",
   "metadata": {},
   "source": [
    "## 1.Getting your data ready: Splitting your data\n",
    "\n",
    "Three main things we have to do:\n",
    "  1. split the data into features and labels (usually 'X' and 'Y')\n",
    "  2. Filling (also called imputing) or disregarding missing values\n",
    "  3. converting non-numerical values to numerical values (also called feature encoding)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a44f7-8d38-464f-a1fb-5fccdb0ad1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline    \n",
    "#so plots will be in our notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d6d35-05ab-45ca-96fe-d958e6507b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose you have some data like colours red,blue,green but actually \n",
    "# the machine cannot understand those non-numerical values you have to convert them into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255d9b6-60f9-4530-a669-a2237b6ff16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hear_disease = pd.read_csv(\"heart_disease_sample (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199784eb-ca78-46e0-91b7-571a7ea80973",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\",axis=1) # axis0-rows, axis1-columns\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9023a-3d25-4c8a-9fd4-b78d3077aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = hear_disease[\"target\"]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57edb448-e004-485c-a326-b310d931ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e0afb-4e3d-49d1-b51a-841fe01aad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ce32d-dca1-4f51-858c-72a2e6f37ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8b87b-c65d-4c41-896e-18c7b66357a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as training set is 80%\n",
    "X.shape, X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e0443-e3b0-4afe-bd13-47d14fca45fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c8f639-d8e8-4406-a05c-7aa4904eb5ce",
   "metadata": {},
   "source": [
    "## Clean, Transform and Reduce data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3dafb-8896-41be-ba38-5a5ae458861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data -> Transform data -> Reduce data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c1824-4e33-40e8-87c5-41dd883bfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you remove some missing field rows, outliers before actually training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087717e-ffff-4851-9151-f20a12d3c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so after this cleaning we transform data to binary so computer cna understand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557bd40-8df2-42fe-9b50-f49280b10cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after transforming we reduce data because the more data, the more cpu, the more energy , \n",
    "# we try to get the same results with less data this data reduction is called dimensionality reduction or column reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b037b9f-bfc6-4e85-bce7-f48e138a113c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93766169-4cf9-43c5-9c8a-8d0a9ef6311a",
   "metadata": {},
   "source": [
    "## Convert data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8866c2f-6e28-4961-91e8-1d42b42cf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"car-sales.csv\")\n",
    "car_sales,len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d559d5-5c2f-4537-b0e8-0f897f92ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales[\"Price\"] = car_sales[\"Price\"].str.replace('[\\$\\,\\.]','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b546b0-c02f-436a-ab90-4572700a09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales[\"Price\"]= car_sales[\"Price\"].str[:-2]\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea111e-0200-4ea2-b477-ed54ebb11f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix - split into X ,Y , so we wnat to guess price from the model\n",
    "X = car_sales.drop(\"Price\",axis=1)\n",
    "Y = car_sales[\"Price\"]\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da60cad-c709-42b7-a5c1-2654aec8a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test data \n",
    "X_train, X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85452a8-14e8-4474-995f-b0ff138f2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a machine learning model \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 90)\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783a28c-9c4a-494d-aacb-228aa4c10a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a32b4c33-e816-4e41-9ab3-a7b8263e4b01",
   "metadata": {},
   "source": [
    "Machine learning models work with numbers, not text.\n",
    "So we must convert categorical (text) data into numbers â†’ this is called encoding.\n",
    "\n",
    "OneHotEncoder converts categories into binary columns (0s and 1s).\n",
    "Why â€œone-hotâ€?\n",
    "Because only ONE column is â€œhotâ€ (1) for each row, the rest are 0.\n",
    "\n",
    "ColumnTransformer lets you apply different transformations to different columns.\n",
    "Apply OneHotEncoder â†’ to categorical columns\n",
    "Keep the rest of the columns â†’ unchanged (passthrough)\n",
    "\n",
    "OneHotEncoder â†’ converts text categories into 0/1 columns\n",
    "ColumnTransformer â†’ tells which columns should be encoded and which should stay the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc748d-f34b-4a3c-975e-3a1f9daf976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because those words are not understood by computer so we have to convert them into numbers\n",
    "# Turn the categories into numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# so actually this transformer takes the categorical_features apply oneHotencoder on them and leaves the remaining passthrough which are not categorical_features\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecc40d-3943-4320-9083-555c3057643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbd6fa-200b-4b8d-ac76-49999f493f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\",\"Colour\",\"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2aceb1-0a64-4424-97cd-c71618625714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets refit the model \n",
    "np.random.seed(42)\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(transformed_X,Y,test_size=0.2)\n",
    "\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98617a59-b4d5-437d-927a-dc0b59f61f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18207c0-0e3c-4552-b6c4-74850778eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc230c09-fc0a-4cce-b43f-558995b5d021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a3883-4ea9-4422-bc8b-52ce98166b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before converting into numbers it was failed to train now we converted into numerical and it worked fine \n",
    "# so now what to do with missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b121c0-1b14-4908-8302-5469d5af55d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "878a4883-94f9-4b47-8c1f-097e5ac7238c",
   "metadata": {},
   "source": [
    "## Handling missing values with pandas\n",
    "\n",
    "1. Fill them with some value (also known as imputation)\n",
    "2. Remove the sample with missing data altogether\n",
    "\n",
    "so actually both are tricky because if we will fill with some data then the data is nto accurate , \n",
    "if we remove then we might work with less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce3e98-4a47-4474-a1f2-de6c66988462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"car-sales-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e1597-7bb1-4396-b2e0-07f21d692068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isna -> fill missing with NaN and sum() indicates number if those in each column\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2884d-9c12-4d41-b503-472d05690cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Price\"] = car_sales_missing[\"Price\"].str.replace('[\\$\\,\\.]','',regex=True)\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768c231-1da4-4da9-a97b-542f561d7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y \n",
    "X = car_sales_missing.drop(\"Price\",axis=1)\n",
    "Y = car_sales_missing[\"Price\"]\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b3f9f-e751-4ccc-82d7-7db21b4ba977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try and convert our data to numbers \n",
    "# because those words are not understood by computer so we have to convert them into numbers\n",
    "# Turn the categories into numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# so actually this transformer takes the categorical_features apply oneHotencoder on them and leaves the remaining passthrough which are not categorical_features\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14cca7-f727-4469-a1d8-b111cafdbd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before tranforming we might get error -> input contains NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f25a5-fd2f-44c7-a509-758477e825a1",
   "metadata": {},
   "source": [
    "### Option 1: Fill missing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0912f9-6b87-4d99-8435-3fea80500b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50a814-a202-4ef3-9ecf-aaddb918e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\",inplace=True)\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\",inplace=True)\n",
    "\n",
    "# Fill the \"Odometer\" column\n",
    "car_sales_missing[\"Odometer\"].fillna(car_sales_missing[\"Odometer\"].mean(),inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"].fillna(4,inplace=True)\n",
    "\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d04592-7cb6-4b91-bb37-361f2b06ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd18f8d-6498-4bab-a49b-c5c01107af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing price value \n",
    "car_sales_missing.dropna(inplace=True)\n",
    "\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352b99c-41d5-4b63-b829-e52ea977c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373c77b-3fa0-4959-b031-e2165d7e1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y \n",
    "X = car_sales_missing.drop(\"Price\",axis=1)\n",
    "Y = car_sales_missing[\"Price\"]\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a913ac-5a38-4868-8215-6dada9acc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try and convert our data to numbers \n",
    "# because those words are not understood by computer so we have to convert them into numbers\n",
    "# Turn the categories into numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# so actually this transformer takes the categorical_features apply oneHotencoder on them and leaves the remaining passthrough which are not categorical_features\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb56109-fd86-4215-9ab2-8dd48922f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## so we used pandas to fill and remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d408ec0-3977-4652-9240-62f93be164de",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744236a-a878-4982-962c-bb62d1f29261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitiate\n",
    "car_sales_missing = pd.read_csv(\"car-sales-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d53f6-c5ef-40d4-ba2a-8608b4fec851",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06942299-3736-45b1-abd5-945755b5c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna() - removes rowws(or columns) that contain missing values (NaN)\n",
    "# if price is missing -> drop that entire row\n",
    "# isna() creates a True/false table \n",
    "# sum() true - 1 , false -0 add them column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37577f7-b2b7-4540-9888-068b14545e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Price\"] = car_sales_missing[\"Price\"].str.replace('[\\$\\,\\.]','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab0aab-911a-4da8-93b3-8f3398f5cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with no labels\n",
    "car_sales_missing.dropna(subset=[\"Price\"],inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b462758-7d7a-4503-9458-5cfdda7046e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and Y \n",
    "X = car_sales_missing.drop(\"Price\",axis=1)\n",
    "Y = car_sales_missing[\"Price\"]\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734cf24-87d6-488e-821e-853b8c42c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values with scikit-learn \n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X[\"Odometer\"] = pd.to_numeric(X[\"Odometer\"], errors=\"coerce\")\n",
    "\n",
    "# fill categorical values with 'missing' and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\",fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\",fill_value=4)\n",
    "numerical_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features=[\"Make\",\"Colour\"]\n",
    "door_features=[\"Doors\"]\n",
    "num_features=[\"Odometer\"]\n",
    "\n",
    "# create an imputer (somethign that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "               (\"cat_imputer\", cat_imputer,cat_features),\n",
    "               (\"door_imputer\",door_imputer,door_features),\n",
    "               (\"numerical_imputer\",numerical_imputer,num_features)\n",
    "           ])\n",
    "\n",
    "# Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e81a0d9a-6cca-478b-bd90-2dc282e013f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filled_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m car_sales_filled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mfilled_X\u001b[49m,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColour\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOdometer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m car_sales_filled\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filled_X' is not defined"
     ]
    }
   ],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X,columns=[\"Make\",\"Colour\",\"Doors\",\"Odometer\"])\n",
    "car_sales_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f523e-7fd5-4edc-affa-68b409c91344",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb15ba1-d35d-424c-8464-3120309db1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because those words are not understood by computer so we have to convert them into numbers\n",
    "# Turn the categories into numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# so actually this transformer takes the categorical_features apply oneHotencoder on them and leaves the remaining passthrough which are not categorical_features\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13043e2d-f5cb-4366-8f84-ba77483fdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we got oru data as numbers and filled ( no missing daat)\n",
    "# lets fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(transformed_X,Y,test_size=0.2)\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c7cb7-d6ea-49d6-8a1b-6ee587b3b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22498f5b-daea-436e-816b-fc0bec98287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_filled),len(car_sales),len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd0ccd-64d4-4e92-a4a9-ea8cbddceab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process of filling missing values is called imputation\n",
    "# process of turning non-numerical values into numerical values is called feature engineering or feature and coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcde5fb-07e4-435e-8a5a-87fc0fe73407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so until now the getting the data ready is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d9aa3-dfb2-447d-9072-a2a869246c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14798a-967e-4207-b7ac-935959af63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now choosing the model before we took randomforestregressor how to choose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c7602-f7d1-4257-8804-7daec6452a9d",
   "metadata": {},
   "source": [
    "## 2. Choosing the right Estimator/algorithm for the problem\n",
    "\n",
    "somethings to note :\n",
    "\n",
    "* Sklearn refers to machine learning models,algorithms as estimators\n",
    "* within these estimators we have classifiers - Classification model and regressors- Regression model\n",
    "* Classification problem - predicting a category (heart disease or not)\n",
    "     *  sometimes you'll see 'clf' (short for calssifier) used as a classification estimator)\n",
    "* Regression problem = predicting a number (selling price of a car)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "122f9509-0278-4028-8cbe-36c9fe030fad",
   "metadata": {},
   "source": [
    " For choosing the model to use : https://scikit-learn.org/stable/machine_learning_map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274310c9-4343-4e8f-a3d3-5e7381f632fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets start with a regression problem \n",
    "## 2.1 picking a machine learning model for a regression problem\n",
    "# ex: california housing dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0692ac7e-b992-47ec-9897-ad3a870ac663",
   "metadata": {},
   "source": [
    "as_frame=True tells sklearn to return the dataset as a pandas DataFrame instead of NumPy arrays.\n",
    "\n",
    "housing.data â†’ pandas DataFrame\n",
    "housing.target â†’ pandas Series\n",
    "housing.frame â†’ full DataFrame (features + target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f68c30-edff-441c-bfa8-6875f0467cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get california housing dataset \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Show keys\n",
    "print(housing.keys())\n",
    "\n",
    "# Show first 5 rows of the dataset\n",
    "housing.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fc0ca28-3649-4696-b86e-89ac9b848f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f73fdb6f-d56a-44ff-a7df-ed5f8249f0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns = housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ada0ee68-4437-4b39-848e-83b1f6c99af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[\"MedHouseVal\"]= housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60c6a0be-2010-4103-a705-897977014709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       " 0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       " 1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       " 2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       " 3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       " 4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       " ...       ...       ...       ...        ...         ...       ...       ...   \n",
       " 20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       " 20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       " 20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       " 20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       " 20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       " \n",
       "        Longitude  \n",
       " 0        -122.23  \n",
       " 1        -122.22  \n",
       " 2        -122.24  \n",
       " 3        -122.25  \n",
       " 4        -122.25  \n",
       " ...          ...  \n",
       " 20635    -121.09  \n",
       " 20636    -121.21  \n",
       " 20637    -121.22  \n",
       " 20638    -121.32  \n",
       " 20639    -121.24  \n",
       " \n",
       " [20640 rows x 8 columns],\n",
       " 0        4.526\n",
       " 1        3.585\n",
       " 2        3.521\n",
       " 3        3.413\n",
       " 4        3.422\n",
       "          ...  \n",
       " 20635    0.781\n",
       " 20636    0.771\n",
       " 20637    0.923\n",
       " 20638    0.847\n",
       " 20639    0.894\n",
       " Name: MedHouseVal, Length: 20640, dtype: float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# setup random seed \n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#create the data\n",
    "X = housing_df.drop(\"MedHouseVal\", axis = 1)\n",
    "Y = housing_df[\"MedHouseVal\"]       # median house price in $100,000s\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1654a429-66f1-433d-a08a-85a58bf5abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing which model to use \n",
    "# this is regression problem so go in that path from teh sklearn cheat sheet \n",
    "# here data is ready -> we are not predicting a category -> we are predicting quantity \n",
    "# next few features should be important we dont know about this so we will try both models \n",
    "# actually advantage of machine learning is we can try different models and check for the model \n",
    "# so here we can try both Lasso and Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe109cbb-56cf-4673-a167-d583fa799ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try Ridge verison first\n",
    "# import algorithm/estimator \n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# initiate and fit the model (on training set)\n",
    "model = Ridge()\n",
    "\n",
    "# training \n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# testing\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56fe2fc4-5370-4f0b-8f23-edd1e95e3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2841671821008396"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try Lasso verison \n",
    "# import algorithm/estimator \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# initiate and fit the model (on training set)\n",
    "model = Lasso()\n",
    "\n",
    "# training \n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# testing\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4dd4457-09d2-44db-bd63-d797913444db",
   "metadata": {},
   "source": [
    "# actually to improve the model\n",
    "1. use more data\n",
    "2. try another model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6528ee9f-787c-463a-ad8c-74b2bc620f93",
   "metadata": {},
   "source": [
    "Ensemble methods : the goal is to combine the predictions of several base estimators \n",
    "built with learning algorithm in order to improve generalizability robustness over a single estimator\n",
    "\n",
    "generalizability is the ability for a machine learning model to predict accurately on unseen data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93969428-48c9-457a-9a7b-a1fc71c72819",
   "metadata": {},
   "source": [
    "# Random Forest is combination of lots of different decision trees \n",
    "we can use Random Forest algo for both classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "856abd99-b10e-4e7c-86d0-71c8249dcb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8051230593157366"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try ensemble model (ensemble is combination of smaller models rather than just a single model)\n",
    "# import the RandomForestRegressor model class from the ensemble module\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# fitting the training data\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# scoring\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df373b82-3cad-45af-937b-44dc66ed7288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea200f37-5b6c-411d-be27-6f9a0ecc3598",
   "metadata": {},
   "source": [
    "## 2.2 Choosing an estimator for a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "097607bf-d12a-4bd3-9fae-1ebbc20f64f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.keys())\n",
    "print(digits.data.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3954ce6-dd63-4d65-86c9-9f642b080c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_df = pd.DataFrame(digits[\"data\"], columns = digits[\"feature_names\"])\n",
    "digits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34191d76-940b-4a4a-b494-414dcfbf827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  Target  \n",
       "0           0.0       0  \n",
       "1           0.0       1  \n",
       "2           0.0       2  \n",
       "3           0.0       3  \n",
       "4           0.0       4  \n",
       "...         ...     ...  \n",
       "1792        0.0       9  \n",
       "1793        0.0       0  \n",
       "1794        0.0       8  \n",
       "1795        0.0       9  \n",
       "1796        0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_df[\"Target\"] = digits[\"target\"]\n",
    "digits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2f83973-6db7-4b52-85f1-a197ea07bc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       " 0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       " 1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       " 2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       " 3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       " 4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       " 1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       " 1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       " 1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       " 1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       " \n",
       "       pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       " 0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       " 3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       " 4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " ...         ...        ...        ...        ...  ...        ...        ...   \n",
       " 1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       " 1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       " 1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       " 1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       " \n",
       "       pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       " 0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       " 1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       " 2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       " 3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       " 4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       " 1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       " 1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       " 1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       " 1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       " \n",
       "       pixel_7_6  pixel_7_7  \n",
       " 0           0.0        0.0  \n",
       " 1           0.0        0.0  \n",
       " 2           9.0        0.0  \n",
       " 3           0.0        0.0  \n",
       " 4           0.0        0.0  \n",
       " ...         ...        ...  \n",
       " 1792        0.0        0.0  \n",
       " 1793        0.0        0.0  \n",
       " 1794        0.0        0.0  \n",
       " 1795        0.0        0.0  \n",
       " 1796        1.0        0.0  \n",
       " \n",
       " [1797 rows x 64 columns],\n",
       " 0       0\n",
       " 1       1\n",
       " 2       2\n",
       " 3       3\n",
       " 4       4\n",
       "        ..\n",
       " 1792    9\n",
       " 1793    0\n",
       " 1794    8\n",
       " 1795    9\n",
       " 1796    8\n",
       " Name: Target, Length: 1797, dtype: int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = digits_df.drop(\"Target\",axis=1)\n",
    "y = digits_df[\"Target\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83037f35-4692-410c-9447-e3eb586750be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e9eb7e5b-d709-4e5d-a175-6ef28c328516",
   "metadata": {},
   "source": [
    "# so now we want classifiers to classify\n",
    "1. Linear classifiers \n",
    "2. Non-linear classifiers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "783ff9bd-7944-4775-ae17-56518ad8e229",
   "metadata": {},
   "source": [
    "# 1. Linear Classifiers\n",
    "Decision boundary = straight line / plane / hyperplane\n",
    "\n",
    "linear seperability,fast,simple,low overfitting\n",
    "\n",
    "models :\n",
    "Linear SVC\n",
    "SGD Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "883a4f9c-476e-4204-b13c-53f27cad55a3",
   "metadata": {},
   "source": [
    "# 2. Non-linear Classifiers\n",
    "Decision boundary = curved / complex shape\n",
    "\n",
    "capture complex patterns,higher accuracy,more computation, higher overfitting risk\n",
    "\n",
    "models :\n",
    "KNN\n",
    "SVC(RBF kernel)\n",
    "RBFSampler + SGD(approximate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aebe1b85-82d4-4805-8903-bbd541ca20a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'â†’' (U+2192) (1510014356.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[49], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Start simple â†’ increase complexity only if needed\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character 'â†’' (U+2192)\n"
     ]
    }
   ],
   "source": [
    "Start simple â†’ increase complexity only if needed\n",
    "Linear classifiers test separability; non-linear classifiers capture complexity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "056bd7b3-55d8-41da-bdb9-1bbfa9a1eae8",
   "metadata": {},
   "source": [
    "| Step | Question                    | Model                |\n",
    "| ---- | --------------------------- | -------------------- |\n",
    "| 1    | Can a line separate data?   | LinearSVC            |\n",
    "| 2    | Need faster linear model?   | SGD                  |\n",
    "| 3    | Local similarity important? | KNN                  |\n",
    "| 4    | Need smooth curves?         | RBF-SVM              |\n",
    "| 5    | RBF too slow?               | Kernel Approximation |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d4f7a76-bab5-4d46-b4cc-8b86220e9fa5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d731f3c-65a4-4851-8531-f43a5405963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before learning these linear and non- linear models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a45a3-441b-4d43-8cc7-a5a63bab9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select suitable model\n",
    "# if you go through that map you can understand lets start with Linear Svc first\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51e55ddd-c5ce-442b-8532-f71047a5b49a",
   "metadata": {},
   "source": [
    "instead of above pipeline and scaler you can directly use the model \n",
    "clf = LinearSVC(ma_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb1a61-5755-4c70-94c2-94d017f56466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try another classifier\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d45ba2-f905-4eed-905e-0b8298eab8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use KNeighbors classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(x_train, y_train)\n",
    "neigh.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3dfb48-d193-4757-9c7b-184254bc55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try SVC(ensemble classifiers)\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd33f1-8701-44f7-b158-a2b44434c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use kernel approximation\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "X_features = rbf_feature.fit_transform(X)\n",
    "clf = SGDClassifier(max_iter=5)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3c7ae19-4d44-4ab3-9fc8-f61c5a43edc1",
   "metadata": {},
   "source": [
    "# 1. if you have structured data, use ensemble methods\n",
    "   Examples: tables, CSVs, features like age, salary, clicks, counts\n",
    "   Best bets: Random Forest, XGBoost, LightGBM, CatBoost\n",
    "  why they shine \n",
    "     Handle missing values and mixed feature types well\n",
    "     Strong temporal or relational structure (time series, graphs)\n",
    "\n",
    "# 2. if you have unstructured data, use deep learning or transfer learning \n",
    "    Unstructured data â†’ Deep learning / Transfer learning\n",
    "    Examples: text, images, audio, video\n",
    "    Text: BERT, RoBERTa, GPT-style models\n",
    "    Images: ResNet, EfficientNet, ViT\n",
    "    Audio: Wav2Vec, Whisper\n",
    "\n",
    "  why they work \n",
    "    automatically learns representations \n",
    "    Transfer learning gives great results even with small datasets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "040b105f-f468-45dd-86cf-b15cc7a92d9c",
   "metadata": {},
   "source": [
    "| Data type   | Start with            | Upgrade to                   |\n",
    "| ----------- | --------------------- | ---------------------------- |\n",
    "| Tabular     | XGBoost / CatBoost    | Neural nets (only if needed) |\n",
    "| Text        | TF-IDF + Logistic Reg | BERT / LLM fine-tuning       |\n",
    "| Images      | CNN from scratch      | Pretrained CNN / ViT         |\n",
    "| Small data  | Classical ML          | Transfer learning            |\n",
    "| Low compute | Ensembles             | DL only if necessary         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f905247-3901-4ce1-904f-cfa3fa91a60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "728faa83-11d6-4338-9cae-d0a8def0f370",
   "metadata": {},
   "source": [
    "# 3. Fit the model/algorithm on our data and use it to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a36e4d-ad1b-4330-a1e0-83bebf7c0a97",
   "metadata": {},
   "source": [
    "### 31. fitting the model\n",
    "* x = features, features variables , data\n",
    "* y = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cf8bd-a3aa-4473-8bd2-4ceaa2514ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "heart_disease = pd.read_csv(\"heart_disease_sample (1).csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf43b73-db73-48af-bf97-e3407bb6fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# make the data\n",
    "X = heart_disease.drop(\"target\",axis=1)\n",
    "Y = heart_disease[\"target\"]\n",
    "\n",
    "# split the data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "# instantiate the classifier \n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# Evaluate the Random forest classifier (use the patterns the model has learned)\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbea861-1810-4be2-afae-ea1bf7a21528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predictions to truth labels to evaluate the model\n",
    "Y_predicted = model.predict(X_test)\n",
    "np.mean(Y_predicted == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f0fe8-97ac-4d96-ba9a-ce46541beea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417a5fc-4bc4-4030-b9d1-ae2052208a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy classification score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1e7f8-3cfc-45f7-a20a-63aef696654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with predict_proba()\n",
    "# it returns probabilities of a classification label\n",
    "# probability estimates - the returned estimates for all classes are ordered by the label of classes\n",
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d4db3-dac8-4947-bc9a-cc57bc2cf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2b821-6524-4607-a848-372bc1455d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so for that predict_proba it is returning the probability of the feature \n",
    "# there for the first row for 1 - 0.58 (it means - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdba710-6771-418d-9140-b4e4c41edefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so when we are confident about the model then use predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "508a2904-139d-4cba-b224-c2973d28b539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use that predict() for regression models as well \n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6ab954b-d8a6-4309-9918-b2cfff7f05a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999302094669"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = housing_df\n",
    "y = housing[\"target\"]\n",
    "\n",
    "# split into training and test sets\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# create model instance\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# fit the model to the data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions \n",
    "y_preds = model.predict(x_test)\n",
    "\n",
    "# find the score \n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77564586-d8a9-4c0c-ac0f-4bbc21499221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6abe4f-cdb2-41e5-820c-620e6728cf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33fa98a4-694c-4f08-bc91-d5dbd405d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00019074459786971705"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb0e42-ec08-467b-8e0f-34a67a235927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
